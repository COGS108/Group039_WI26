{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with your team list and their contributions. Note that this will change over the course of the checkpoints\n",
    "\n",
    "This is a modified [CRediT taxonomy of contributions](https://credit.niso.org). For each group member please list how they contributed to this project using these terms:\n",
    "> Analysis, Background research, Conceptualization, Data curation, Experimental investigation, Methodology, Project administration, Software, Visualization, Writing – original draft, Writing – review & editing\n",
    "\n",
    "Example team list and credits:\n",
    "- Alice Anderson: Conceptualization, Data curation, Methodology, Writing - original draft\n",
    "- Bob Barker:  Analysis, Software, Visualization\n",
    "- Charlie Chang: Project administration, Software, Writing - review & editing\n",
    "- Dani Delgado: Analysis, Background research, Visualization, Writing - original draft"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work (Revised)\n",
    "\n",
    "Basketball performance reflects both learned skill (shooting, decision making) and physical constraints (reach, mass, speed). Because the NBA systematically records player measurements and season level box-score outcomes, it provides a strong setting for testing whether **height is associated with performance** and whether that association differs by **position**, where roles and typical body types differ (e.g., rim protection vs. playmaking). Prior work on lineups and “small-ball” strategy supports the idea that the value of body size is **context dependent**, motivating our decision to analyze results **within positions** rather than assuming one global height–performance relationship. <sup>[5](#fn5)</sup>\n",
    "\n",
    "A key challenge is operationalizing “achievement” in a way that is measurable and comparable across players and seasons. We will use **Player Efficiency Rating (PER)** as our **primary outcome** because it is a widely used, per-minute composite of box-score production normalized to a league average value (≈15). However, PER is not a complete measure of total value: it is **box-score based** and is commonly criticized for **under-representing defense** beyond steals/blocks/rebounds, ignoring off-ball defense and matchup effects, and potentially over-rewarding certain offensive box-score patterns. Because of these limitations, we treat PER as a convenient summary, not a definitive “true value”, and will also report **secondary outcomes** (points, rebounds, assists per game) to show *how* any height association manifests across different skill domains and roles. <sup>[6](#fn6)</sup>\n",
    "\n",
    "Beyond height alone, prior work suggests that reach related measures especially **wingspan relative to height** can matter for basketball outcomes. For example, reporting on research published in the *Journal of Anthropology of Sport and Physical Education*, a UC Berkeley news summary describes evidence that arm-length-to-height proportions are associated with elite athletic success in the NBA, suggesting that “functional length” may matter beyond listed height. <sup>[7](#fn7)</sup> Complementing this, sport analytics work focusing on wingspan reports potential tradeoffs: longer wingspans may support defensive impact while being linked to reduced shooting accuracy in some analyses, typically evaluated using **regression-style modeling** (i.e., modeling performance outcomes as a function of wingspan while controlling for other factors). <sup>[8](#fn8)</sup> These findings directly shape our project direction: if height effects weaken after controlling for role/position, wingspan (or wingspan-to-height ratio) may better capture “usable reach” relevant to rebounding/defense—so we will include wingspan when available and explicitly acknowledge it as a potential confound or alternative predictor.\n",
    "\n",
    "Relatedly, draft combine research demonstrates that anthropometric variables differ systematically by position and can be associated with selection outcomes, often using group comparisons and predictive modeling to evaluate discriminative factors. For instance, research on NBA Draft Combine participants identifies which anthropometric and fitness measures best distinguish draft outcomes across positions. <sup>[9](#fn9)</sup> While draft status is not the same as NBA on-court production, this literature reinforces two points that matter for our modeling plan: (1) anthropometrics are intertwined with positional role and selection processes, and (2) any “height effect” should be tested with **controls** and **position-stratified analysis** to reduce misleading aggregate conclusions.\n",
    "\n",
    "Finally, prior work in this area commonly relies on **correlation** and **multivariable regression** frameworks to quantify associations between physical traits and outcomes (e.g., Pearson correlations for bivariate relationships; linear regression to control for confounds). Because our research question centers on whether the height–performance relationship is **position-dependent**, we will extend the typical approach by explicitly testing a **Height × Position interaction** in a regression model, alongside controls such as minutes played and age/experience when available. This allows us to distinguish (a) overall associations from (b) role-specific patterns—aligning our method directly with what prior work suggests, while addressing the common limitation that many analyses either do not stratify by position or do not formally test whether relationships differ across roles.\n",
    "\n",
    "---\n",
    "\n",
    "<a name=\"fn5\"></a>5. Zhang et al. (and related work summarized in): *Clustering Performances in Elite Basketball Matches According to the Anthropometric Features of the Line-ups Based on Big Data Technology.* https://pmc.ncbi.nlm.nih.gov/articles/PMC9309682/\n",
    "\n",
    "<a name=\"fn6\"></a>6. Wikipedia. “Player efficiency rating.” https://en.wikipedia.org/wiki/Player_efficiency_rating\n",
    "\n",
    "<a name=\"fn7\"></a>7. University of California. “Study shows wingspan has correlation to athletic prowess in NBA, MMA.” https://www.universityofcalifornia.edu/news/study-shows-wingspan-has-correlation-athletic-prowess-nba-mma\n",
    "\n",
    "<a name=\"fn8\"></a>8. SportRxiv preprint on wingspan and performance tradeoffs (defense vs. shooting). https://sportrxiv.org/index.php/server/preprint/view/238\n",
    "\n",
    "<a name=\"fn9\"></a>9. NBA Draft Combine / anthropometrics study (position differences and draft outcomes). https://pmc.ncbi.nlm.nih.gov/articles/PMC6820507/\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "  - Description of the variables most relevant to this project\n",
    "  - Descriptions of any shortcomings this dataset has with repsect to the project\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - same as above\n",
    "- etc\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/airline-safety/airline-safety.csv', 'filename':'airline-safety.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 \n",
    "\n",
    "See instructions above for Dataset #1.  Feel free to keep adding as many more datasets as you need.  Put each new dataset in its own section just like these. \n",
    "\n",
    "Lastly if you do have multiple datasets, add another section where you demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets\n",
    "\n",
    "Please note that you can always keep adding more datasets in the future if these datasets you turn in for the checkpoint aren't sufficient.  The goal here is demonstrate that you can obtain and wrangle data.  You are not tied down to only use what you turn in right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project uses publicly available NBA player statistics and does not include any private or sensitive personal information. Since the data come from official league sources and public databases, issues related to informed consent and personal privacy are minimal. However, there are still several ethical considerations in how we define performance and interpret our results.\n",
    "\n",
    "First, we create a composite performance index using standardized values of PER, points per game, rebounds per game, and assists per game. Although this helps combine different performance metrics into one measure, assigning equal weight to these variables is a subjective choice. Different positions in basketball naturally emphasize different skills, so some players may be advantaged or disadvantaged depending on how the index is constructed. In addition, PER itself has known limitations and may not fully represent defensive contributions or team impact. Therefore, our performance index should be understood as an approximation rather than a complete measure of player value.\n",
    "\n",
    "Second, our regression analysis assumes a linear relationship between height and the constructed performance index. This may oversimplify the true relationship. There may be nonlinear patterns or interaction effects between height and position that are not fully captured in our model. In addition, other factors such as team role, experience, or injuries are not included in the dataset, which may introduce omitted variable bias. For this reason, our findings describe statistical associations rather than causal conclusions.\n",
    "\n",
    "Third, there is a possibility of unintended interpretation. A statistical relationship between height and performance does not imply that taller players are inherently superior. Our analysis is exploratory and academic in nature, and we will be careful not to make deterministic or discriminatory claims based on physical attributes.\n",
    "\n",
    "Finally, we recognize that quantitative statistics cannot capture qualitative aspects of basketball, such as leadership, communication, or defensive positioning. These limitations will be clearly acknowledged when presenting our results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Communication channel & response time: We will use Discord as our primary communication channel. We aim to respond within 24 hours on weekdays. Important decisions and updates will be summarized in the main Discord channel so everyone stays aligned.*\n",
    "* *Meeting schedule: We will meet at least once per week. Meetings will be held virtually unless the team agrees to meet in person. Each meeting will have a short agenda and end with clear action items and owners.*\n",
    "* *Task ownership: Every task will have a clear owner + deadline. If someone cannot meet a deadline, they will notify the group at least 24 hours in advance and propose a new plan.*\n",
    "* *Work quality & reproducibility: Before pushing, members will ensure their work is clear, documented, and the notebook can run from top-to-bottom.*\n",
    "* *Division of labor: We will split work fairly across writing, coding, and analysis. Everyone will contribute to both content (writing) and technical work as appropriate.*\n",
    "* *Respect & collaboration: We will communicate respectfully, assume good intent, and give constructive feedback. Disagreements will be discussed calmly with evidence (data/rubric) guiding decisions.*\n",
    "* *Conflict resolution: If a conflict cannot be resolved within the group, we will escalate early (TA/instructor) rather than waiting until deadlines.*\n",
    "* *Accountability: We will post a brief progress update in Discord before each weekly meeting. If someone is blocked, we will ask for help early rather than waiting until the deadline.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/4  |  1 PM | Finalize ProjectProposal.ipynb draft; add citations/footnotes; delete rubric cell; Restart & Run All  | Final review proposal (RQ, hypothesis, data plan, ethics, timeline); assign roles for Data Checkpoint | \n",
    "| 2/9  |  7 PM |  Download/get data; store in data/ (or script to fetch); write initial loading code | Confirm unit of analysis; decide cleaning rules (missing values/outliers); split wrangling tasks | \n",
    "| 2/11  | 7 PM  | Clean/wrangle v1; document steps; create codebook; draft 01 sections (dataset description + source citation)  | Review wrangling; check reproducibility; plan remaining tasks for 01-DataCheckpoint.ipynb   |\n",
    "| 2/14  | 6 PM  | Finish 01-DataCheckpoint.ipynb (data source, ideal vs real dataset, storage/organization, wrangling summary) | Restart & Run All; polish writing; confirm what to submit   |\n",
    "| 2/18  | 4 PM  | Commit/push current progress | Discuss division of labor and working on assigned parts |\n",
    "| 2/18  | 9 PM  | Submit Data Checkpoint via git commit/push | Post-submit plan: list EDA questions + required plots; assign EDA plot owners |\n",
    "| 2/23  | 7 PM | EDA plots v2 + captions; start 02-EDACheckpoint.ipynb write-up | Decide final metrics + baseline method(s); confirm train/test or statistical test plan |\n",
    "| 3/4  | 7 PM  | Submit EDA Checkpoint via git commit/push | Lock in final analysis pipeline; assign final notebook sections and responsibilities |\n",
    "| 3/8  | 7 PM  | Run main analysis/model (baseline + improved); save key tables/figures in results/ | Debug issues; check assumptions/validity; decide what goes into Results vs Discussion |\n",
    "| 3/11  | 7 PM  | Draft 03-FinalProject.ipynb (methods, results, discussion, limitations, ethics) | Peer review writing; ensure narrative matches rubric; plan video outline |\n",
    "| 3/15  | 7 PM  | Finalize notebook visuals + text; Restart & Run All; clean outputs; draft video script/slides | Final QA checklist; confirm all team contributions; prepare final push |\n",
    "| 3/18  | 7 PM  | Submit Final project + Video; complete Post-course + Team Evaluation surveys | Confirm submission success; backup final files |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
